{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import selfies as sf\n",
    "import exmol\n",
    "from dataclasses import dataclass\n",
    "from rdkit.Chem.Draw import rdDepictor\n",
    "\n",
    "rdDepictor.SetPreferCoordGen(True)\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\n",
    "    \"dark\",\n",
    "    {\n",
    "        \"xtick.bottom\": True,\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.color\": \"#666666\",\n",
    "        \"ytick.color\": \"#666666\",\n",
    "        \"axes.edgecolor\": \"#666666\",\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"figure.dpi\": 300,\n",
    "    },\n",
    ")\n",
    "color_cycle = [\"#1BBC9B\", \"#F06060\", \"#5C4B51\", \"#F3B562\", \"#6e5687\"]\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(color=color_cycle)\n",
    "soldata = pd.read_csv(\n",
    "    \"https://github.com/whitead/dmol-book/raw/master/data/curated-solubility-dataset.csv\"\n",
    ")\n",
    "features_start_at = list(soldata.columns).index(\"MolWt\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scramble them\n",
    "# Reduced for CI!\n",
    "soldata = soldata.sample(frac=0.01, random_state=0).reset_index(drop=True)\n",
    "soldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_list = [sf.encoder(exmol.sanitize_smiles(s)[1]) for s in soldata.SMILES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = set(exmol.get_basic_alphabet())\n",
    "data_vocab = set(sf.get_alphabet_from_selfies([s for s in selfies_list if s is not None]))\n",
    "vocab = ['[Nop]']\n",
    "vocab.extend(list(data_vocab.union(basic)))\n",
    "vocab_stoi = {o:i for o,i in zip(vocab, range(len(vocab)))}\n",
    "#vocab_stoi['[nop]'] = 0 \n",
    "\n",
    "def selfies2ints(s):\n",
    "    result = []\n",
    "    for token in sf.split_selfies(s):\n",
    "        if token == '.':\n",
    "            continue #?\n",
    "        if token in vocab_stoi:\n",
    "            result.append(vocab_stoi[token])\n",
    "        else:\n",
    "            result.append(np.nan)\n",
    "            #print('Warning')\n",
    "    return result\n",
    "\n",
    "def ints2selfies(v):\n",
    "    return ''.join([vocab[i] for i in v])\n",
    "\n",
    "# test them out\n",
    "s = selfies_list[0]\n",
    "print('selfies:', s)\n",
    "v = selfies2ints(s)\n",
    "print('selfies2ints:', v)\n",
    "so = ints2selfies(v)\n",
    "print('ints2selfes:', so)\n",
    "assert so == s.replace('.','') #make sure '.' is removed from Selfies string during assertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    vocab_size: int\n",
    "    example_number: int\n",
    "    batch_size: int\n",
    "    buffer_size: int\n",
    "    embedding_dim: int\n",
    "    rnn_units: int\n",
    "    hidden_dim: int\n",
    "\n",
    "\n",
    "config = Config(\n",
    "    vocab_size=len(vocab),\n",
    "    example_number=len(selfies_list),\n",
    "    batch_size=16,\n",
    "    buffer_size=10000,\n",
    "    embedding_dim=256,\n",
    "    hidden_dim=128,\n",
    "    rnn_units=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get sequences\n",
    "encoded = [selfies2ints(s) for s in selfies_list if s is not None]\n",
    "padded_seqs = tf.keras.preprocessing.sequence.pad_sequences(encoded, padding=\"post\")\n",
    "\n",
    "# Now build dataset\n",
    "data = tf.data.Dataset.from_tensor_slices(\n",
    "    (padded_seqs, soldata.Solubility.iloc[[bool(s) for s in selfies_list]].values)\n",
    ")\n",
    "# now split into val, test, train and batch\n",
    "N = len(data)\n",
    "split = int(0.1 * N)\n",
    "test_data = data.take(split).batch(config.batch_size)\n",
    "nontest = data.skip(split)\n",
    "val_data, train_data = nontest.take(split).batch(config.batch_size), nontest.skip(\n",
    "    split\n",
    ").shuffle(config.buffer_size).batch(config.batch_size).prefetch(\n",
    "    tf.data.experimental.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# make embedding and indicate that 0 should be treated as padding mask\n",
    "model.add(\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=config.vocab_size, output_dim=config.embedding_dim, mask_zero=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# RNN layer\n",
    "model.add(tf.keras.layers.GRU(config.rnn_units))\n",
    "# a dense hidden layer\n",
    "model.add(tf.keras.layers.Dense(config.hidden_dim, activation=\"relu\"))\n",
    "# regression, so no activation\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.optimizers.Adam(1e-4), loss=\"mean_squared_error\")\n",
    "result = model.fit(train_data, validation_data=val_data, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result.history[\"loss\"], label=\"training\")\n",
    "plt.plot(result.history[\"val_loss\"], label=\"validation\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = []\n",
    "test_y = []\n",
    "for x, y in test_data:\n",
    "    yhat.extend(model(x).numpy().flatten())\n",
    "    test_y.extend(y.numpy().flatten())\n",
    "yhat = np.array(yhat)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "# plot test data\n",
    "plt.plot(test_y, test_y, \":\")\n",
    "plt.plot(test_y, yhat, \".\")\n",
    "plt.text(min(y) - 7, max(y) - 2, f\"correlation = {np.corrcoef(test_y, yhat)[0,1]:.3f}\")\n",
    "plt.text(min(y) - 7, max(y) - 3, f\"loss = {np.sqrt(np.mean((test_y - yhat)**2)):.3f}\")\n",
    "plt.title(\"Testing Data\")\n",
    "plt.savefig(\"rnn-fit.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CF explanation:\n",
    "\n",
    "In the following example let's say we would like our molecules to return a solubility value of -3.5. Here we use `counterstone` algorithm to create counter factual explanations. In other words, we would like to see what are the minimal mutations that could to be done to our input structure to get our desired solubility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_function(smile_list, selfies):\n",
    "    encoded = [selfies2ints(s) for s in selfies]\n",
    "    # check for nans\n",
    "    valid = [1.0 if sum(e) > 0 else np.nan for e in encoded]\n",
    "    encoded = [np.nan_to_num(e, nan=0) for e in encoded]\n",
    "    padded_seqs = tf.keras.preprocessing.sequence.pad_sequences(encoded, padding=\"post\")\n",
    "    labels = np.reshape(model.predict(padded_seqs), (-1))\n",
    "    return labels * valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_function([], [\"[C][C][O]\", \"[C][C][Nop][O]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoned_kwargs = {\n",
    "    \"num_samples\": 2500,\n",
    "    \"alphabet\": exmol.get_basic_alphabet(),\n",
    "    \"max_mutations\": 2,\n",
    "}\n",
    "space = exmol.sample_space(\n",
    "    soldata.SMILES[4], predictor_function, stoned_kwargs=stoned_kwargs\n",
    ")\n",
    "exps = exmol.rcf_explain(space, 0.5, nmols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkw = {\"figsize\": (10, 3)}\n",
    "exmol.plot_cf(exps, figure_kwargs=fkw, mol_size=(450, 400), nrows=1)\n",
    "plt.savefig(\"rnn-simple.png\", bbox_inches=\"tight\", dpi=180)\n",
    "svg = exmol.insert_svg(exps, mol_fontsize=16)\n",
    "with open(\"rnn-simple.svg\", \"w\") as f:\n",
    "    f.write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkw = {\"figsize\": (10, 4)}\n",
    "font = {\"family\": \"normal\", \"weight\": \"normal\", \"size\": 22}\n",
    "\n",
    "exmol.plot_space(space, exps, figure_kwargs=fkw, mol_size=(100, 100), offset=1)\n",
    "ax = plt.gca()\n",
    "plt.colorbar(\n",
    "    ax.get_children()[1],\n",
    "    ax=[ax],\n",
    "    label=\"Solubility [Log M]\",\n",
    "    location=\"left\",\n",
    "    shrink=0.8,\n",
    ")\n",
    "plt.savefig(\"rnn-space.png\", bbox_inches=\"tight\", dpi=180)\n",
    "svg = exmol.insert_svg(exps, mol_fontsize=16)\n",
    "with open(\"svg_figs/rnn-space.svg\", \"w\") as f:\n",
    "    f.write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = exmol.sample_space(soldata.SMILES[4], predictor_function, preset=\"wide\")\n",
    "exps = exmol.rcf_explain(space, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkw = {\"figsize\": (8, 6)}\n",
    "font = {\"family\": \"normal\", \"weight\": \"normal\", \"size\": 22}\n",
    "\n",
    "\n",
    "exmol.plot_space(space, exps, figure_kwargs=fkw, mol_size=(200, 200), offset=1)\n",
    "ax = plt.gca()\n",
    "plt.colorbar(ax.get_children()[1], ax=[ax], location=\"left\", label=\"Solubility [Log M]\")\n",
    "plt.savefig(\"rnn-wide.png\", bbox_inches=\"tight\", dpi=180)\n",
    "svg = exmol.insert_svg(exps, mol_fontsize=16)\n",
    "with open(\"rnn-space-wide.svg\", \"w\") as f:\n",
    "    f.write(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure showing effect of mutation number and Alphabet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = []\n",
    "spaces = []\n",
    "for i in [1, 3, 5]:\n",
    "    stoned_kwargs = {\n",
    "        \"num_samples\": 2500,\n",
    "        \"alphabet\": exmol.get_basic_alphabet(),\n",
    "        \"min_mutations\": i,\n",
    "        \"max_mutations\": i,\n",
    "    }\n",
    "    space = exmol.sample_space(\n",
    "        soldata.SMILES[4], predictor_function, stoned_kwargs=stoned_kwargs\n",
    "    )\n",
    "    spaces.append(space)\n",
    "    e = exmol.rcf_explain(space, nmols=2)\n",
    "    if len(exps) == 0:\n",
    "        exps.append(e[0])\n",
    "    for ei in e:\n",
    "        if not ei.is_origin and \"Decrease\" in ei.label:\n",
    "            ei.label = f\"Mutations = {i}\"\n",
    "            exps.append(ei)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkw = {\"figsize\": (10, 4)}\n",
    "exmol.plot_cf(exps, figure_kwargs=fkw, mol_fontsize=26, mol_size=(400, 400), nrows=1)\n",
    "plt.savefig(\"rnn-mutations.png\", bbox_inches=\"tight\", dpi=180)\n",
    "svg = exmol.insert_svg(exps, mol_fontsize=16)\n",
    "with open(\"rnn-mutations.svg\", \"w\") as f:\n",
    "    f.write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(8, 3), dpi=180, squeeze=True, sharey=True)\n",
    "for i, n in enumerate([1, 3, 5]):\n",
    "    axs[i].hist([e.similarity for e in spaces[i][1:]], bins=99, edgecolor=\"none\")\n",
    "    axs[i].set_title(f\"Mutations = {n}\")\n",
    "    axs[i].set_xlim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"rnn-mutation-hist.png\", bbox_inches=\"tight\", dpi=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = exmol.get_basic_alphabet()\n",
    "train = sf.get_alphabet_from_selfies(selfies_list)\n",
    "wide = sf.get_semantic_robust_alphabet()\n",
    "\n",
    "alphs = {\"Basic\": basic, \"Training Data\": train, \"SELFIES\": wide}\n",
    "\n",
    "exps = []\n",
    "for l, a in alphs.items():\n",
    "    stoned_kwargs = {\"num_samples\": 2500 // 2, \"alphabet\": a, \"max_mutations\": 2}\n",
    "    space = exmol.sample_space(\n",
    "        soldata.SMILES[4], predictor_function, stoned_kwargs=stoned_kwargs\n",
    "    )\n",
    "    e = exmol.rcf_explain(space, nmols=2)\n",
    "    if len(exps) == 0:\n",
    "        exps.append(e[0])\n",
    "    for ei in e:\n",
    "        if not ei.is_origin and \"Decrease\" in ei.label:\n",
    "            ei.label = f\"Alphabet = {l}\"\n",
    "            exps.append(ei)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkw = {\"figsize\": (10, 4)}\n",
    "exmol.plot_cf(exps, figure_kwargs=fkw, mol_fontsize=26, mol_size=(400, 400), nrows=1)\n",
    "plt.savefig(\"rnn-alphabets.png\", bbox_inches=\"tight\", dpi=180)\n",
    "svg = exmol.insert_svg(exps, mol_fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
