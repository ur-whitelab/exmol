{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to Generate Explanations for Different Scents\n",
    "Using exmol package: https://github.com/ur-whitelab/exmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from typing import *\n",
    "import exmol\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit, rdkit.Chem, rdkit.Chem.rdDepictor, rdkit.Chem.Draw\n",
    "from IPython.display import display, SVG\n",
    "from rdkit.Chem.Draw import MolToImage as mol2img, DrawMorganBit  # type: ignore\n",
    "from rdkit.Chem import rdchem, MACCSkeys, AllChem  # type: ignore\n",
    "import skunk\n",
    "import cairosvg\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pyrfume  # for loading dataset\n",
    "\n",
    "# Packages needed for GNN model (model used when creating spaces)\n",
    "##not needed if generating descriptor explanations or NLEs using a previously created sample space\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import tensorflow as tf\n",
    "\n",
    "# Plotting style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf\",\n",
    "    \"IBMPlexMono-Regular.ttf\",\n",
    ")\n",
    "fe = font_manager.FontEntry(fname=\"IBMPlexMono-Regular.ttf\", name=\"plexmono\")\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.facecolor\": \"#f5f4e9\",\n",
    "        \"grid.color\": \"#AAAAAA\",\n",
    "        \"axes.edgecolor\": \"#333333\",\n",
    "        \"figure.facecolor\": \"#FFFFFF\",\n",
    "        \"axes.grid\": False,\n",
    "        \"axes.prop_cycle\": plt.cycler(\"color\", plt.cm.Dark2.colors),\n",
    "        \"font.family\": fe.name,\n",
    "        \"figure.figsize\": (3.5, 3.5 / 1.2),\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.bottom\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN model related code\n",
    "Code below modified from example code given in the \"Predicting DFT Energies with GNNs\", \"Interpretability and Deep Learning\" sections of \"Deep Learning for Molecules and Materials\" textbook (https://dmol.pub/applied/QM9.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for GNN model (parameters being read in)\n",
    "node_feat_length = 256\n",
    "message_feat_length = 256\n",
    "graph_feat_length = 512\n",
    "weights_stddevGNN = 0.01\n",
    "\n",
    "# Load data from pyrfume\n",
    "scentdata = scentdata = pyrfume.load_data(\n",
    "    \"leffingwell/leffingwell_data.csv\", remote=True\n",
    ")\n",
    "\n",
    "\n",
    "# Code to generate list of all scent labels (scentClasses)\n",
    "numMolecules = len(scentdata.odor_labels_filtered)\n",
    "numClasses = 112  # No odorless class\n",
    "scentClasses = pd.read_csv(\"scentClasses.csv\")\n",
    "scentClasses = scentClasses[\"Scent\"].tolist()\n",
    "moleculeScentList = []\n",
    "for i in range(numMolecules):\n",
    "    scentString = scentdata.odor_labels_filtered[i]\n",
    "    temp = scentString.replace(\"[\", \"\")\n",
    "    temp = temp.replace(\"]\", \"\")\n",
    "    temp = temp.replace(\"'\", \"\")\n",
    "    temp = temp.replace(\" \", \"\")\n",
    "    scentList = temp.split(\",\")\n",
    "    if \"odorless\" in scentList:\n",
    "        scentList.remove(\"odorless\")\n",
    "    moleculeScentList.append(scentList)\n",
    "\n",
    "\n",
    "def gen_smiles2graph(sml):\n",
    "    \"\"\"Argument for the RD2NX function should be a valid SMILES sequence\n",
    "    returns: the graph\n",
    "    \"\"\"\n",
    "    m = rdkit.Chem.MolFromSmiles(sml)\n",
    "    m = rdkit.Chem.AddHs(m)\n",
    "    order_string = {\n",
    "        rdkit.Chem.rdchem.BondType.SINGLE: 1,\n",
    "        rdkit.Chem.rdchem.BondType.DOUBLE: 2,\n",
    "        rdkit.Chem.rdchem.BondType.TRIPLE: 3,\n",
    "        rdkit.Chem.rdchem.BondType.AROMATIC: 4,\n",
    "    }\n",
    "    N = len(list(m.GetAtoms()))\n",
    "    nodes = np.zeros((N, node_feat_length))\n",
    "    for i in m.GetAtoms():\n",
    "        nodes[i.GetIdx(), i.GetAtomicNum()] = 1\n",
    "        # Add in whether atom is in a ring or not for one-hot encoding\n",
    "        if i.IsInRing():\n",
    "            nodes[i.GetIdx(), -1] = 1\n",
    "\n",
    "    adj = np.zeros((N, N))\n",
    "    for j in m.GetBonds():\n",
    "        u = min(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        v = max(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        order = j.GetBondType()\n",
    "        if order in order_string:\n",
    "            order = order_string[order]\n",
    "        else:\n",
    "            raise Warning(\"Ignoring bond order\" + order)\n",
    "        adj[u, v] = 1\n",
    "        adj[v, u] = 1\n",
    "    adj += np.eye(N)\n",
    "    return nodes, adj\n",
    "\n",
    "\n",
    "# Function that creates label vector given list of strings describing scent of molecule as input\n",
    "# Each index in label vector corresponds to specific scent -> if output has a 0 at index i, then molecule does not have scent i\n",
    "# If label vector has 1 at index i, then molecule does have scent i\n",
    "\n",
    "\n",
    "def createLabelVector(scentsList):\n",
    "    # Find class index in label vector that each scent corresponds to & update label for that molecule to 1\n",
    "    labelVector = np.zeros(numClasses)\n",
    "    for j in range(len(scentsList)):\n",
    "        # Find class index\n",
    "        classIndex = scentClasses.index(scentsList[j])\n",
    "        # print(classIndex)\n",
    "        # print(scentsList[j])\n",
    "        # print(scentClasses[classIndex])\n",
    "        # Update label vector\n",
    "        labelVector[classIndex] = 1\n",
    "    return labelVector\n",
    "\n",
    "\n",
    "def generateGraphs():\n",
    "    for i in range(numMolecules):\n",
    "        graph = gen_smiles2graph(scentdata.smiles[i])\n",
    "        labels = createLabelVector(moleculeScentList[i])\n",
    "        yield graph, labels\n",
    "\n",
    "\n",
    "# Get graph data for training, testing & validation sets\n",
    "data = tf.data.Dataset.from_generator(\n",
    "    generateGraphs,\n",
    "    output_types=((tf.float32, tf.float32), tf.float32),\n",
    "    output_shapes=(\n",
    "        (tf.TensorShape([None, node_feat_length]), tf.TensorShape([None, None])),\n",
    "        tf.TensorShape([None]),\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "class GNNLayer(hk.Module):\n",
    "    def __init__(self, output_size, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # split input into nodes, edges & features\n",
    "        nodes, edges, features = inputs\n",
    "        # Nodes is of shape (N, Nf) --> N = # atoms, Nf = node_feature_length\n",
    "        # Edges is of shape (N,N) (adjacency matrix)\n",
    "        # Features is of shape (Gf) --> Gf = graph_feature_length\n",
    "\n",
    "        graph_feature_len = features.shape[-1]  # graph_feature_len (Gf)\n",
    "        node_feature_len = nodes.shape[-1]  # node_feature_len (Nf)\n",
    "        message_feature_len = message_feat_length  # message_feature_length (Mf)\n",
    "\n",
    "        # Initialize weights\n",
    "        w_init = hk.initializers.RandomNormal(stddev=weights_stddevGNN)\n",
    "\n",
    "        # we is of shape (Nf,Mf)\n",
    "        we = hk.get_parameter(\n",
    "            \"we\", shape=[node_feature_len, message_feature_len], init=w_init\n",
    "        )\n",
    "\n",
    "        # b is of shape (Mf)\n",
    "        b = hk.get_parameter(\"b\", shape=[message_feature_len], init=w_init)\n",
    "\n",
    "        # wv is of shape (Mf,Nf)\n",
    "        wv = hk.get_parameter(\n",
    "            \"wv\", shape=[message_feature_len, node_feature_len], init=w_init\n",
    "        )\n",
    "\n",
    "        # wu is of shape (Nf,Gf)\n",
    "        wu = hk.get_parameter(\n",
    "            \"wu\", shape=[node_feature_len, graph_feature_len], init=w_init\n",
    "        )\n",
    "\n",
    "        # make nodes be N x N x Nf so we can just multiply directly (N = number of atoms)\n",
    "        # ek is now shaped N x N x Mf\n",
    "        ek = jax.nn.leaky_relu(\n",
    "            b\n",
    "            + jnp.repeat(nodes[jnp.newaxis, ...], nodes.shape[0], axis=0)\n",
    "            @ we\n",
    "            * edges[..., None]\n",
    "        )\n",
    "\n",
    "        # Uncomment lines below to update edges (also edit return line so new_edges is returned)\n",
    "        # Update edges, use jnp.any to have new_edges be of shape N x N\n",
    "        # new_edges = jnp.any(ek, axis=-1)\n",
    "\n",
    "        # Normalize over edge features w/layer normalization\n",
    "        # new_edges = hk.LayerNorm(axis=[0,1], create_scale=False, create_offset=False, eps=1e-05)(new_edges)\n",
    "\n",
    "        # take sum over neighbors to get ebar shape = Nf x Mf\n",
    "        ebar = jnp.sum(ek, axis=1)\n",
    "\n",
    "        # dense layer for new nodes to get new_nodes shape = N x Nf\n",
    "        new_nodes = jax.nn.leaky_relu(ebar @ wv) + nodes  # Use leaky ReLU\n",
    "\n",
    "        # Normalize over node features w/layer normalization\n",
    "        new_nodes = hk.LayerNorm(\n",
    "            axis=[0, 1], create_scale=False, create_offset=False, eps=1e-05\n",
    "        )(new_nodes)\n",
    "\n",
    "        # sum over nodes to get shape features so global_node_features shape = Nf\n",
    "        global_node_features = jnp.sum(new_nodes, axis=0)\n",
    "\n",
    "        # dense layer for new features so new_features shape = Gf\n",
    "        new_features = (\n",
    "            jax.nn.leaky_relu(global_node_features @ wu) + features\n",
    "        )  # Use leaky ReLU for activation\n",
    "\n",
    "        # just return features for ease of use\n",
    "        return new_nodes, edges, new_features\n",
    "\n",
    "\n",
    "def model_fn(x):\n",
    "    nodes, edges = x\n",
    "    features = jnp.ones(graph_feat_length)\n",
    "    x = nodes, edges, features\n",
    "\n",
    "    # NOTE: If edited num_GNN_layers, need to edit code below (increase or decrease # times have x = GNNLayer(...))\n",
    "    # 4 GNN layers\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "\n",
    "    # 2 dense layers\n",
    "    logits = hk.Linear(numClasses)(x[-1])\n",
    "    # logits = jax.nn.relu(logits) #ReLU activation between dense layer\n",
    "    logits = hk.Linear(numClasses)(logits)\n",
    "\n",
    "    return logits  # Model now returns logits\n",
    "\n",
    "\n",
    "model = hk.without_apply_rng(hk.transform(model_fn))\n",
    "\n",
    "# Initialize model\n",
    "rng = jax.random.PRNGKey(0)\n",
    "sampleData = data.take(1)\n",
    "for dataVal in sampleData:  # Look into later how to get larger set\n",
    "    (nodes_i, edges_i), yi = dataVal\n",
    "nodes_i = nodes_i.numpy()\n",
    "edges_i = edges_i.numpy()\n",
    "\n",
    "yi = yi.numpy()\n",
    "xi = (nodes_i, edges_i)\n",
    "\n",
    "params = model.init(rng, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimal parameters for GNN model\n",
    "print(\"Edit fileName to change parameters being loaded\")\n",
    "fileName = \"optParams_dry-waterfall-17.npy\"  # Currently optimal parameters, edit when get better model\n",
    "paramsArr = jnp.load(fileName, allow_pickle=True)\n",
    "opt_params = {\n",
    "    \"gnn_layer\": {\n",
    "        \"b\": paramsArr[0],\n",
    "        \"we\": paramsArr[1],\n",
    "        \"wu\": paramsArr[2],\n",
    "        \"wv\": paramsArr[3],\n",
    "    },\n",
    "    \"gnn_layer_1\": {\n",
    "        \"b\": paramsArr[4],\n",
    "        \"we\": paramsArr[5],\n",
    "        \"wu\": paramsArr[6],\n",
    "        \"wv\": paramsArr[7],\n",
    "    },\n",
    "    \"gnn_layer_2\": {\n",
    "        \"b\": paramsArr[8],\n",
    "        \"we\": paramsArr[9],\n",
    "        \"wu\": paramsArr[10],\n",
    "        \"wv\": paramsArr[11],\n",
    "    },\n",
    "    \"gnn_layer_3\": {\n",
    "        \"b\": paramsArr[12],\n",
    "        \"we\": paramsArr[13],\n",
    "        \"wu\": paramsArr[14],\n",
    "        \"wv\": paramsArr[15],\n",
    "    },\n",
    "    \"linear\": {\"b\": paramsArr[16], \"w\": paramsArr[17]},\n",
    "    \"linear_1\": {\"b\": paramsArr[18], \"w\": paramsArr[19]},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation & plotting related functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified functions used when selecting counterfactuals such that only the label for the selected scent is flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_examples(cond, examples, nmols):\n",
    "    result = []\n",
    "\n",
    "    # similarity filtered by if cluster/counter\n",
    "    def cluster_score(e, i):\n",
    "        return (e.cluster == i) * cond(e) * e.similarity\n",
    "\n",
    "    clusters = set([e.cluster for e in examples])\n",
    "    for i in clusters:\n",
    "        close_counter = max(examples, key=lambda e, i=i: cluster_score(e, i))\n",
    "        # check if actually is (since call could have been zero)\n",
    "        if cluster_score(close_counter, i):\n",
    "            result.append(close_counter)\n",
    "\n",
    "    # trim, in case we had too many cluster\n",
    "    result = sorted(result, key=lambda v: v.similarity * cond(v), reverse=True)[:nmols]\n",
    "\n",
    "    # fill in remaining\n",
    "    ncount = sum([cond(e) for e in result])\n",
    "    fill = max(0, nmols - ncount)\n",
    "    result.extend(\n",
    "        sorted(examples, key=lambda v: v.similarity * cond(v), reverse=True)[:fill]\n",
    "    )\n",
    "\n",
    "    return list(filter(cond, result))\n",
    "\n",
    "\n",
    "def cf_explain(examples, nmols):\n",
    "    \"\"\"From given :obj:`Examples<Example>`, find closest counterfactuals (see :doc:`index`)\n",
    "    :param examples: Output from :func:`sample_space`\n",
    "    :param nmols: Desired number of molecules\n",
    "    \"\"\"\n",
    "\n",
    "    def is_counter(e):\n",
    "        return e.yhat != examples[0].yhat\n",
    "\n",
    "    scent_classes = np.array([x for x in scentClasses])\n",
    "    origin_labels = np.array(\n",
    "        [my_model(examples[0].smiles, scent) for scent in scent_classes]\n",
    "    )\n",
    "    print(origin_labels)\n",
    "    #     print([scentClasses[i] for i, x in enumerate(origin_labels) if x==1])\n",
    "    print(scent_classes[origin_labels == 1])\n",
    "\n",
    "    selection = _select_examples(is_counter, examples[1:], len(examples[1:]))\n",
    "    selection = sorted(\n",
    "        selection, key=lambda v: v.similarity * is_counter(v), reverse=True\n",
    "    )\n",
    "\n",
    "    result = []\n",
    "    for e in selection:\n",
    "        labels = np.array([my_model(e.smiles, scent) for scent in scent_classes])\n",
    "        flips = origin_labels != labels\n",
    "        print(f\"flipped labels: {scent_classes[flips]}\")\n",
    "        flip_count = np.sum(flips)\n",
    "        if flip_count < 2 and e.similarity > 0.3:\n",
    "            result.append(e)\n",
    "        if len(result) == nmols:\n",
    "            break\n",
    "\n",
    "    for i, r in enumerate(result):\n",
    "        r.label = f\"Counterfactual {i+1}\"\n",
    "\n",
    "    return examples[:1] + result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine similarity function used to compute similarity for descriptor explanations with multiple base molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute dot product with labels\n",
    "def cosine_similarity_base(df, bases, llists):\n",
    "    df[\"label_dot\"] = np.array(0.0)\n",
    "    for j, row in df.iterrows():\n",
    "        if j in bases:\n",
    "            base = j\n",
    "            df[\"label_dot\"][j] = 1\n",
    "        else:\n",
    "            # cosine similarity\n",
    "            if np.all(llists[j] == 0):\n",
    "                df[\"label_dot\"][j] = 0\n",
    "                continue\n",
    "            df[\"label_dot\"][j] = (\n",
    "                llists[base]\n",
    "                @ llists[j]\n",
    "                / np.linalg.norm(llists[base])\n",
    "                / np.linalg.norm(llists[j])\n",
    "            )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions used for generating plots with model fit & creating a list of exmol Examples from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this cell taken from Solubility-RNN.ipynb notebook from https://github.com/ur-whitelab/exmol/blob/main/paper2_LIME/Solubility-RNN.ipynb\n",
    "def weighted_mean(x, w):\n",
    "    return np.sum(x * w) / np.sum(w)\n",
    "\n",
    "\n",
    "def weighted_cov(x, y, w):\n",
    "    return np.sum(w * (x - weighted_mean(x, w)) * (y - weighted_mean(y, w))) / np.sum(w)\n",
    "\n",
    "\n",
    "def weighted_correlation(x, y, w):\n",
    "    return weighted_cov(x, y, w) / np.sqrt(\n",
    "        weighted_cov(x, x, w) * weighted_cov(y, y, w)\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_correlation(space, descriptor_type):\n",
    "    beta = exmol.lime_explain(space, descriptor_type)\n",
    "    fkw = {\"figsize\": (6, 4)}\n",
    "    font = {\"family\": \"normal\", \"weight\": \"normal\", \"size\": 16}\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    matplotlib.rc(\"axes\", titlesize=12)\n",
    "    matplotlib.rc(\"font\", size=16)\n",
    "    ax_dict = fig.subplot_mosaic(\"AABBB\")\n",
    "    # Plot space by fit\n",
    "    base_examples = [e for e in space if e.is_origin == True]\n",
    "    svg = plot_space_by_fit_multiple_bases(\n",
    "        space,\n",
    "        base_examples,\n",
    "        figure_kwargs=fkw,\n",
    "        mol_size=(200, 200),\n",
    "        offset=1,\n",
    "        ax=ax_dict[\"B\"],\n",
    "        beta=beta,\n",
    "    )\n",
    "    # Compute y_wls\n",
    "    w = np.array([1 / (1 + (1 / (e.similarity + 0.000001) - 1) ** 5) for e in space])\n",
    "    non_zero = w > 10 ** (-6)\n",
    "    w = w[non_zero]\n",
    "    N = w.shape[0]\n",
    "\n",
    "    ys = np.array([e.yhat for e in space])[non_zero].reshape(N).astype(float)\n",
    "    x_mat = np.array([list(e.descriptors.descriptors) for e in space])[\n",
    "        non_zero\n",
    "    ].reshape(N, -1)\n",
    "    y_wls = x_mat @ beta\n",
    "    y_wls += np.mean(ys)\n",
    "\n",
    "    lower = np.min(ys)\n",
    "    higher = np.max(ys)\n",
    "\n",
    "    # set transparency using w\n",
    "    norm = plt.Normalize(min(w), max(w))\n",
    "    cmap = plt.cm.Oranges(w)\n",
    "    cmap[:, -1] = w\n",
    "\n",
    "    corr = weighted_correlation(ys, y_wls, w)\n",
    "\n",
    "    ax_dict[\"A\"].plot(\n",
    "        np.linspace(lower, higher, 100),\n",
    "        np.linspace(lower, higher, 100),\n",
    "        \"--\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    sc = ax_dict[\"A\"].scatter(ys, y_wls, s=50, marker=\".\", c=cmap, cmap=cmap)\n",
    "    ax_dict[\"A\"].text(max(ys) - 10, min(ys) + 1, f\"weighted \\ncorrelation = {corr:.3f}\")\n",
    "    ax_dict[\"A\"].set_xlabel(r\"$\\hat{y}$\")\n",
    "    ax_dict[\"A\"].set_ylabel(r\"$g$\")\n",
    "    ax_dict[\"A\"].set_title(\"Weighted Least Squares Fit\")\n",
    "    ax_dict[\"A\"].set_xlim(lower - 0.1, higher + 0.1)\n",
    "    ax_dict[\"A\"].set_ylim(lower - 0.1, higher + 0.1)\n",
    "    ax_dict[\"A\"].set_aspect(1.0 / ax_dict[\"A\"].get_data_ratio(), adjustable=\"box\")\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.Oranges, norm=norm)\n",
    "    cbar = plt.colorbar(sm, orientation=\"horizontal\", pad=0.15, ax=ax_dict[\"A\"])\n",
    "    cbar.set_label(\"Chemical similarity\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified function for multiple bases based on plot_space_by_fit function in exmol plot_utils.py file\n",
    "def plot_space_by_fit_multiple_bases(\n",
    "    examples,\n",
    "    exps,\n",
    "    beta,\n",
    "    mol_size=(200, 200),\n",
    "    mol_fontsize=8,\n",
    "    offset=0,\n",
    "    ax=None,\n",
    "    figure_kwargs=None,\n",
    "    cartoon=False,\n",
    "    rasterized=False,\n",
    "):\n",
    "    imgs = exmol.plot_utils._mol_images(exps, mol_size, mol_fontsize)\n",
    "    if figure_kwargs is None:\n",
    "        figure_kwargs = {\"figsize\": (12, 8)}\n",
    "    base_color = \"gray\"\n",
    "    if ax is None:\n",
    "        ax = plt.figure(**figure_kwargs).gca()\n",
    "\n",
    "    yhat = np.array([e.yhat for e in examples]).astype(float)\n",
    "    yhat -= np.mean(yhat)\n",
    "    x_mat = np.array([list(e.descriptors.descriptors) for e in examples]).reshape(\n",
    "        len(examples), -1\n",
    "    )\n",
    "    y = x_mat @ beta\n",
    "    # use resids as colors\n",
    "    colors = (yhat - y) ** 2\n",
    "    normalizer = plt.Normalize(min(colors), max(colors))\n",
    "    cmap = \"PuBu_r\"\n",
    "\n",
    "    space_x = [e.position[0] for e in examples]\n",
    "    space_y = [e.position[1] for e in examples]\n",
    "    if cartoon:\n",
    "        # plot shading, lines, front\n",
    "        ax.scatter(space_x, space_y, 50, \"0.0\", lw=2, rasterized=rasterized)\n",
    "        ax.scatter(space_x, space_y, 50, \"1.0\", lw=0, rasterized=rasterized)\n",
    "        ax.scatter(\n",
    "            space_x,\n",
    "            space_y,\n",
    "            50,\n",
    "            c=normalizer(colors),\n",
    "            cmap=cmap,\n",
    "            lw=2,\n",
    "            alpha=0.1,\n",
    "            rasterized=rasterized,\n",
    "        )\n",
    "    else:\n",
    "        im = ax.scatter(\n",
    "            space_x,\n",
    "            space_y,\n",
    "            40,\n",
    "            c=normalizer(colors),\n",
    "            cmap=cmap,\n",
    "            edgecolors=\"grey\",\n",
    "            linewidth=0.25,\n",
    "        )\n",
    "    ax.set_aspect(1.0 / ax.get_data_ratio(), adjustable=\"box\")\n",
    "    cbar = plt.colorbar(im, orientation=\"horizontal\", aspect=35, pad=0.05)\n",
    "    cbar.set_label(\"squared error\")\n",
    "\n",
    "    # now plot cfs/annotated points\n",
    "    ax.scatter(\n",
    "        [e.position[0] for e in exps],\n",
    "        [e.position[1] for e in exps],\n",
    "        c=normalizer([e.yhat for e in exps]),\n",
    "        cmap=cmap,\n",
    "        edgecolors=\"black\",\n",
    "    )\n",
    "\n",
    "    x = np.array([e.position[0] for e in exps])\n",
    "    y = np.array([e.position[1] for e in exps])\n",
    "\n",
    "    titles = []\n",
    "    colors = []\n",
    "    for e in exps:\n",
    "        if not e.is_origin:\n",
    "            titles.append(f\"Similarity = {e.similarity:.2f}\\nf(x)={e.yhat:.3f}\")\n",
    "            colors.append(cast(any, base_color))\n",
    "        else:\n",
    "            titles.append(f\"Base \\nf(x)={e.yhat:.3f}\")\n",
    "            colors.append(cast(any, base_color))\n",
    "    # exmol.plot_utils._image_scatter(x, y, imgs, titles, colors, ax, offset=offset)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_aspect(\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createExampleListfromDataFrame(data):\n",
    "    exampleList = []  # list[exmol.Example]()\n",
    "    for i in range(len(data.index)):\n",
    "        # Since reading position values from csv file, data.position is a string - need to convert to list of floats\n",
    "        positionString = data.position.tolist()[i]\n",
    "        positionString = positionString.replace(\"[\", \"\")\n",
    "        positionString = positionString.replace(\"]\", \"\")\n",
    "        positionList = positionString.split(\" \")\n",
    "        # remove empty string ('') elements in positionList\n",
    "        while \"\" in positionList:\n",
    "            positionList.remove(\"\")\n",
    "        positions = [float(p) for p in positionList]\n",
    "        # using weighted tanimoto with dot product\n",
    "        exampleList.append(\n",
    "            exmol.Example(\n",
    "                data.smiles.tolist()[i],\n",
    "                data.selfies.tolist()[i],\n",
    "                data.similarity.tolist()[i],\n",
    "                data.yhat.tolist()[i],\n",
    "                data.index.tolist()[i],\n",
    "                positions,\n",
    "                data.is_origin.tolist()[i],\n",
    "                data.cluster.tolist()[i],\n",
    "                data.label.tolist()[i],\n",
    "            )\n",
    "        )\n",
    "    return exampleList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create modified alphabet to use when creating explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modified alphabet to use\n",
    "alphabet = exmol.get_basic_alphabet()\n",
    "to_remove = []\n",
    "# remove [B],[#B],[=B]\n",
    "to_remove.extend([\"[B]\", \"[#B]\", \"[=B]\"])\n",
    "\n",
    "# remove [I],[F],[Cl], [Br]\n",
    "to_remove.extend([\"[I]\", \"[F]\", \"[Cl]\", \"[Br]\"])\n",
    "\n",
    "alphabet -= set(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that alphabet does not contain boron, iodine, fluorine, bromine nor chlorine\n",
    "\"\"\"\n",
    "print(alphabet)\n",
    "\n",
    "boronInAlphabet = (\"[#B]\" in alphabet) and (\"[B]\" in alphabet) and (\"[=B]\" in alphabet)\n",
    "iodineInAlphabet = (\"[I]\" in alphabet)\n",
    "fluorineInAlphabet = (\"[F]\" in alphabet)\n",
    "bromineInAlphabet = (\"[Br]\" in alphabet)\n",
    "chlorineInAlphabet = (\"[Cl]\" in alphabet)\n",
    "\n",
    "#Boron is in exmol basic alphabet\n",
    "print(\"Check that using modified basic alphabet (i.e. no Boron, Iodine, Fluorine, Bromine, nor Chlorine)\")\n",
    "print(f\"Boron is in basic alphabet? {boronInAlphabet}\")\n",
    "print(f\"Iodine is in basic alphabet? {iodineInAlphabet}\")\n",
    "print(f\"Fluorine is in basic alphabet? {fluorineInAlphabet}\")\n",
    "print(f\"Bromine is in basic alphabet? {bromineInAlphabet}\")\n",
    "print(f\"Chlorine is in basic alphabet? {chlorineInAlphabet}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating counterfactual explanations for ethyl benzoate (\"fruity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For counterfactuals, need hard yhat values - read in thresholds from csv file\n",
    "thresholds = pd.read_csv(\n",
    "    \"ThresholdsForMaxF1_OdorlessClassRemoved_dry-waterfall-17_trainAndValid.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model function that takes in SMILES string and scent string as input (rather than molecular graph + parameter)\n",
    "# Output is prediction on whether molecule has a certain scent (1) or not (0)\n",
    "def my_model(smilesString, scentString):\n",
    "    molecularGraph = gen_smiles2graph(smilesString)\n",
    "    pos = scentClasses.index(scentString)\n",
    "    thresholdIndex_scent = thresholds.index[thresholds.Scent == scentString].tolist()\n",
    "    threshold = thresholds.Threshold[thresholdIndex_scent].tolist()[\n",
    "        0\n",
    "    ]  # Threshold is the one that maximizes the F1 score\n",
    "    pred = jax.nn.sigmoid(model.apply(opt_params, molecularGraph))[pos]\n",
    "    if pred > threshold:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Molecules being examined/generating counterfactuals for:\n",
    "fruity_ethylbenzoate = \"CCOC(=O)C1=CC=CC=C1\"  # Ethyl benzoate (https://pubchem.ncbi.nlm.nih.gov/compound/Ethyl-benzoate#section=InChI)\n",
    "\n",
    "fatty_24decadienal = \"CCCCCC=CC=CC=O\"  # 2,4 Decadienal (https://pubchem.ncbi.nlm.nih.gov/compound/2_4-Decadienal#section=InChIKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment code below to generate ethyl benzoate counterfactuals around fruity\n",
    "\"\"\"\n",
    "samples_ethylbenzoate_fruity = exmol.sample_space(\n",
    "    fruity_ethylbenzoate,\n",
    "    lambda smi, sel: my_model(smi, \"fruity\"),\n",
    "    batched=False,\n",
    "    preset=\"medium\",\n",
    "    num_samples=20000,\n",
    "    method_kwargs= {'alphabet': alphabet}\n",
    ")\n",
    "\n",
    "cfs_ethylbenzoate_fruity = cf_explain(samples_ethylbenzoate_fruity, nmols=1)\n",
    "exmol.plot_cf(cfs_ethylbenzoate_fruity[:2], figure_kwargs = {'figsize': (10,8)}, mol_size=(300, 300), nrows = 1)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in ethyl benzoate cfs file & create image\n",
    "cfs_ethylbenzoate_fruity = createExampleListfromDataFrame(\n",
    "    pd.read_csv(\"cfs_ethylbenzoate_fruity.csv\")\n",
    ")\n",
    "\n",
    "# Uncomment lines below to save results to csv\n",
    "# cfs_ethylbenzoate_fruity_data = pd.DataFrame(cfs_ethylbenzoate_fruity)\n",
    "# cfs_ethylbenzoate_fruity_data.to_csv(\"cfs_ethylbenzoate_fruity.csv\", index=False)\n",
    "# samples_ethylbenzoate_fruity_data = pd.DataFrame(samples_ethylbenzoate_fruity)\n",
    "# samples_ethylbenzoate_fruity_data.to_csv(\"samples_ethylbenzoate_fruity.csv\", index=False)\n",
    "\n",
    "exmol.plot_cf(\n",
    "    cfs_ethylbenzoate_fruity[:2],\n",
    "    figure_kwargs={\"figsize\": (10, 8)},\n",
    "    mol_size=(300, 300),\n",
    "    nrows=1,\n",
    ")\n",
    "plt.show()\n",
    "# plt.savefig(\"cfs_ethylbenzoate_fruity.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate descriptor explanations & natural language explanations for \"fatty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes in a SMILES string for a molecule and returns the logit predictions for all scent classes\n",
    "def my_model_allScents_logits(smilesString):\n",
    "    molecularGraph = gen_smiles2graph(smilesString)\n",
    "    logits_predictions = model.apply(opt_params, molecularGraph)\n",
    "    return logits_predictions\n",
    "\n",
    "\n",
    "# Function takes in a SMILES string for a molecule and returns the logit predictions for the specified scent\n",
    "def my_model_logits(smilesString, scentString):\n",
    "    molecularGraph = gen_smiles2graph(smilesString)\n",
    "    pos = scentClasses.index(scentString)\n",
    "    pred_logits = model.apply(opt_params, molecularGraph)[pos]\n",
    "    return pred_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create sample space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment code in cell below to generate sample space\n",
    "\"\"\"\n",
    "#For each positive example, generate sample space (using STONED) around that example (use that example as the base molecule)\n",
    "space_total = []\n",
    "scent = 'fatty'\n",
    "for i in range(numMolecules): #sample space created using positive examples\n",
    "    molecule = scentdata.smiles[i]\n",
    "    if(moleculeScentList[i].count(scent) == 1): \n",
    "        sampleSpace = exmol.sample_space(molecule, lambda smi, sel: my_model_logits(smi,scent), batched=False, preset='medium', num_samples=200, method_kwargs= {'alphabet': alphabet})\n",
    "        space_total.extend(sampleSpace)\n",
    "\n",
    "space_total = pd.DataFrame(space_total)\n",
    "\n",
    "#Get predictions for all scent classes for all molecules in the space\n",
    "predictions_logits = []\n",
    "mols = space_total['smiles']\n",
    "for mol in mols:\n",
    "    preds_logits = my_model_allScents_logits(mol)\n",
    "    predictions_logits.append(preds_logits)\n",
    "\n",
    "#Save the space along with scent class predictions to a csv file\n",
    "scentClassesNamesWithLogits = []\n",
    "for c in scentClasses:\n",
    "    scentLogitString = f'{c} + logits'\n",
    "    scentClassesNamesWithLogits.append(scentLogitString)\n",
    "\n",
    "space_total[scentClassesNamesWithLogits] = predictions_logits\n",
    "scentFileName = f'space_{scent}.csv'\n",
    "space_total.to_csv(scentFileName)\n",
    "space_total.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in sample space from csv file & create list of exmol Examples from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download file for \"fatty\" space from figshare\n",
    "filename, headers = urllib.request.urlretrieve(\n",
    "    \"https://figshare.com/ndownloader/files/38472275\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scent = \"fatty\"\n",
    "# NOTE: below reading in a subset of the \"fatty\" sample space from figshare, code not working right now\n",
    "df = pd.read_csv(\n",
    "    filename,\n",
    "    usecols=np.arange(1, 11),\n",
    ")\n",
    "labels = pd.read_csv(\n",
    "    filename,\n",
    "    usecols=np.append([1], np.arange(11, 123)),\n",
    ")\n",
    "llists = labels.to_numpy()[:, 1:]\n",
    "bases = list(df[df[\"is_origin\"] == True].index)\n",
    "\n",
    "df = cosine_similarity_base(df, bases, llists)\n",
    "df[\"similarity\"] = df[\"similarity\"] * df[\"label_dot\"]\n",
    "\n",
    "# Use smaller set of data (just to check code does not crash) - comment out line below when generating results\n",
    "df = df.sample(frac=0.2, random_state=0).reset_index(drop=True)\n",
    "\n",
    "samples = createExampleListfromDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete pandas dataframe to save space\n",
    "colNames = df.columns.values.tolist()\n",
    "for c in colNames:\n",
    "    del df[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create descriptor explanation plots for \"fatty\" & plot model fit for each explanatory model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ECFP = exmol.lime_explain(\n",
    "    samples, descriptor_type=\"ECFP\"\n",
    ")  # create ECFP descriptor explanation\n",
    "\n",
    "svg_ECFP = exmol.plot_descriptors(\n",
    "    samples, figure_kwargs={\"figsize\": (9, 5)}, return_svg=True\n",
    ")\n",
    "cairosvg.svg2png(svg_ECFP, write_to=f\"{scent}_ecfp.png\", background_color=\"white\")\n",
    "\n",
    "base_examples = [e for e in samples if e.is_origin == True]\n",
    "\n",
    "plot_correlation(samples, \"ECFP\")  # plot ECFP model fit\n",
    "# plt.savefig(f'{scent}_ECFPfitAndCorrelation.png', bbox_inches=\"tight\", transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_MACCS = exmol.lime_explain(\n",
    "    samples, descriptor_type=\"MACCS\"\n",
    ")  # create MACCS descriptor explanation\n",
    "\n",
    "svg_MACCS = exmol.plot_descriptors(\n",
    "    samples, figure_kwargs={\"figsize\": (9, 5)}, return_svg=True\n",
    ")\n",
    "cairosvg.svg2png(svg_MACCS, write_to=f\"{scent}_maccs.png\", background_color=\"white\")\n",
    "\n",
    "base_examples = [e for e in samples if e.is_origin == True]\n",
    "\n",
    "plot_correlation(samples, \"MACCS\")  # plot MACCS model fit\n",
    "# plt.savefig(f'{scent}_MACCSfitAndCorrelation.png', bbox_inches=\"tight\", transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create natural language explanations for \"fatty\" scent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmol.lime_explain(samples, \"ecfp\")\n",
    "s1_ecfp = exmol.text_explain(samples, \"ecfp\", presence_thresh=0.1)\n",
    "exmol.lime_explain(samples, \"maccs\")\n",
    "s2_maccs = exmol.text_explain(samples, \"maccs\", presence_thresh=0.1)\n",
    "\n",
    "# print(f's1_ecfp: {s1_ecfp}\\n')\n",
    "# print(f's2_maccs: {s2_maccs}\\n')\n",
    "\n",
    "explanation_list = exmol.merge_text_explains(s1_ecfp, s2_maccs, filter=1.96)[:5]\n",
    "\n",
    "# explanation_list = exmol.merge_text_explains(ecfp_standardized,maccs_standardized, filter=1.96)[:5]\n",
    "nle = exmol.text_explain_generate(explanation_list, f\"{scent} scent\")\n",
    "print(nle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional code to examine positive examples for the \"fatty\" scent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_examples = [e for e in samples if e.is_origin]\n",
    "rdkit.Chem.Draw.MolsToGridImage(\n",
    "    [rdkit.Chem.MolFromSmiles(s.smiles) for s in base_examples], molsPerRow=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maccs_string = \"Is there a C=O double bond?\"\n",
    "count = 0\n",
    "for base_mol in base_examples:\n",
    "    pos_desc = base_mol.descriptors.descriptor_names.index(maccs_string)\n",
    "    desc = base_mol.descriptors.descriptors[pos_desc]\n",
    "    # print(desc, base_mol.descriptors.descriptor_names[pos_desc])\n",
    "    if desc == 1:\n",
    "        count += 1\n",
    "print(\n",
    "    f'For the \"fatty\" base molecules, {count}/{len(base_examples)} match the descriptor: {maccs_string}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
