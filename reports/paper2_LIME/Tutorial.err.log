Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/asyncio/base_events.py", line 691, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
print(exmol.text_explain_generate(e, property_name="active"))
------------------


[31m---------------------------------------------------------------------------[39m
[31mOpenAIError[39m                               Traceback (most recent call last)
[36mCell[39m[36m [39m[32mIn[11][39m[32m, line 1[39m
[32m----> [39m[32m1[39m [38;5;28mprint[39m([43mexmol[49m[43m.[49m[43mtext_explain_generate[49m[43m([49m[43me[49m[43m,[49m[43m [49m[43mproperty_name[49m[43m=[49m[33;43m"[39;49m[33;43mactive[39;49m[33;43m"[39;49m[43m)[49m)

[36mFile [39m[32m/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/exmol/exmol.py:1486[39m, in [36mtext_explain_generate[39m[34m(text_explanations, property_name, llm_model, single)[39m
[32m   1477[39m prompt = prompt_template.format([38;5;28mproperty[39m=property_name, text=text)
[32m   1479[39m messages = [
[32m   1480[39m     {
[32m   1481[39m         [33m"[39m[33mrole[39m[33m"[39m: [33m"[39m[33msystem[39m[33m"[39m,
[32m   (...)[39m[32m   1484[39m     {[33m"[39m[33mrole[39m[33m"[39m: [33m"[39m[33muser[39m[33m"[39m, [33m"[39m[33mcontent[39m[33m"[39m: prompt},
[32m   1485[39m ]
[32m-> [39m[32m1486[39m response = [43mopenai[49m[43m.[49m[43mchat[49m[43m.[49m[43mcompletions[49m.create(
[32m   1487[39m     model=llm_model,
[32m   1488[39m     messages=messages,
[32m   1489[39m     temperature=[32m0.05[39m,
[32m   1490[39m )
[32m   1492[39m [38;5;28;01mreturn[39;00m response.choices[[32m0[39m].message.content

[36mFile [39m[32m/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/openai/_utils/_proxy.py:20[39m, in [36mLazyProxy.__getattr__[39m[34m(self, attr)[39m
[32m     19[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34m__getattr__[39m([38;5;28mself[39m, attr: [38;5;28mstr[39m) -> [38;5;28mobject[39m:
[32m---> [39m[32m20[39m     proxied = [38;5;28;43mself[39;49m[43m.[49m[43m__get_proxied__[49m[43m([49m[43m)[49m
[32m     21[39m     [38;5;28;01mif[39;00m [38;5;28misinstance[39m(proxied, LazyProxy):
[32m     22[39m         [38;5;28;01mreturn[39;00m proxied  [38;5;66;03m# pyright: ignore[39;00m

[36mFile [39m[32m/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/openai/_utils/_proxy.py:55[39m, in [36mLazyProxy.__get_proxied__[39m[34m(self)[39m
[32m     54[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34m__get_proxied__[39m([38;5;28mself[39m) -> T:
[32m---> [39m[32m55[39m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[43m.[49m[43m__load__[49m[43m([49m[43m)[49m

[36mFile [39m[32m/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/openai/_module_client.py:12[39m, in [36mChatProxy.__load__[39m[34m(self)[39m
[32m     10[39m [38;5;129m@override[39m
[32m     11[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34m__load__[39m([38;5;28mself[39m) -> resources.Chat:
[32m---> [39m[32m12[39m     [38;5;28;01mreturn[39;00m [43m_load_client[49m[43m([49m[43m)[49m.chat

[36mFile [39m[32m/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/openai/__init__.py:329[39m, in [36m_load_client[39m[34m()[39m
[32m    313[39m         _client = _AzureModuleClient(  [38;5;66;03m# type: ignore[39;00m
[32m    314[39m             api_version=api_version,
[32m    315[39m             azure_endpoint=azure_endpoint,
[32m   (...)[39m[32m    325[39m             http_client=http_client,
[32m    326[39m         )
[32m    327[39m         [38;5;28;01mreturn[39;00m _client
[32m--> [39m[32m329[39m     _client = [43m_ModuleClient[49m[43m([49m
[32m    330[39m [43m        [49m[43mapi_key[49m[43m=[49m[43mapi_key[49m[43m,[49m
[32m    331[39m [43m        [49m[43morganization[49m[43m=[49m[43morganization[49m[43m,[49m
[32m    332[39m [43m        [49m[43mproject[49m[43m=[49m[43mproject[49m[43m,[49m
[32m    333[39m [43m        [49m[43mbase_url[49m[43m=[49m[43mbase_url[49m[43m,[49m
[32m    334[39m [43m        [49m[43mtimeout[49m[43m=[49m[43mtimeout[49m[43m,[49m
[32m    335[39m [43m        [49m[43mmax_retries[49m[43m=[49m[43mmax_retries[49m[43m,[49m
[32m    336[39m [43m        [49m[43mdefault_headers[49m[43m=[49m[43mdefault_headers[49m[43m,[49m
[32m    337[39m [43m        [49m[43mdefault_query[49m[43m=[49m[43mdefault_query[49m[43m,[49m
[32m    338[39m [43m        [49m[43mhttp_client[49m[43m=[49m[43mhttp_client[49m[43m,[49m
[32m    339[39m [43m    [49m[43m)[49m
[32m    340[39m     [38;5;28;01mreturn[39;00m _client
[32m    342[39m [38;5;28;01mreturn[39;00m _client

[36mFile [39m[32m/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/openai/_client.py:114[39m, in [36mOpenAI.__init__[39m[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)[39m
[32m    112[39m     api_key = os.environ.get([33m"[39m[33mOPENAI_API_KEY[39m[33m"[39m)
[32m    113[39m [38;5;28;01mif[39;00m api_key [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[32m--> [39m[32m114[39m     [38;5;28;01mraise[39;00m OpenAIError(
[32m    115[39m         [33m"[39m[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable[39m[33m"[39m
[32m    116[39m     )
[32m    117[39m [38;5;28mself[39m.api_key = api_key
[32m    119[39m [38;5;28;01mif[39;00m organization [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:

[31mOpenAIError[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable

